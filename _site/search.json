[
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "blogs/index.html",
    "href": "blogs/index.html",
    "title": "Intro to Random Forest in RStudio",
    "section": "",
    "text": "I’ve always found Random Forest to be a fascinating and robust machine learning technique, ideal for both classification and regression tasks. It’s like crafting a forest of decision trees where each tree contributes to a more accurate and generalized prediction. Recently, I delved into implementing a Random Forest model in RStudio, and here, I’ll share my experience using the well-known iris dataset.\nRStudio has been my go-to for exploring machine learning models, and Random Forest was no exception. The iris dataset, a staple in R’s dataset collection, was my dataset of choice for this exploration.\nStep 1: Installing and Loading Packages\n\nlibrary(randomForest)\n\nrandomForest 4.7-1.1\n\n\nType rfNews() to see new features/changes/bug fixes.\n\nlibrary(ggplot2)\n\n\nAttaching package: 'ggplot2'\n\n\nThe following object is masked from 'package:randomForest':\n\n    margin\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following object is masked from 'package:randomForest':\n\n    combine\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\nStep 2: Loading the Dataset\n\ndata(\"iris\")\n\nStep 3: Exploring the Dataset\n\ncolnames(iris)\n\n[1] \"Sepal.Length\" \"Sepal.Width\"  \"Petal.Length\" \"Petal.Width\"  \"Species\"     \n\nstr(iris)\n\n'data.frame':   150 obs. of  5 variables:\n $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\n $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n $ Species     : Factor w/ 3 levels \"setosa\",\"versicolor\",..: 1 1 1 1 1 1 1 1 1 1 ...\n\nsummary(iris)\n\n  Sepal.Length    Sepal.Width     Petal.Length    Petal.Width   \n Min.   :4.300   Min.   :2.000   Min.   :1.000   Min.   :0.100  \n 1st Qu.:5.100   1st Qu.:2.800   1st Qu.:1.600   1st Qu.:0.300  \n Median :5.800   Median :3.000   Median :4.350   Median :1.300  \n Mean   :5.843   Mean   :3.057   Mean   :3.758   Mean   :1.199  \n 3rd Qu.:6.400   3rd Qu.:3.300   3rd Qu.:5.100   3rd Qu.:1.800  \n Max.   :7.900   Max.   :4.400   Max.   :6.900   Max.   :2.500  \n       Species  \n setosa    :50  \n versicolor:50  \n virginica :50  \n                \n                \n                \n\n\nStep 4: Visualizing the Data\nTo get a better grasp of the data distribution, I created some visualizations.\n\npar(mfrow = c(2, 2), mar = c(4, 4, 2, 1))\nboxplot(iris$Sepal.Length, main = \"Sepal Length\",col = \"green\", border = \"black\")\nboxplot(iris$Sepal.Width, main = \"Sepal Width\",col = \"green\", border = \"black\")\nboxplot(iris$Petal.Length, main = \"Petal Length\",col = \"green\", border = \"black\")\nboxplot(iris$Petal.Width, main = \"Petal Width\",col = \"green\", border = \"black\")\n\n\n\n\nStep 5: Examining Relationships\nI wanted to explore relationships between variables, particularly focusing on how different features correlate with iris species. For this, scatterplots are excellent.\n\npairs(iris[1:4], main = \"Iris Data - Pairwise Scatterplot\", \n      pch = 21, bg = c(\"red\", \"green3\", \"blue\")[unclass(iris$Species)])\n\n\n\n\nStep 6: Building the Random Forest Model\n\nset.seed(123)  # For reproducibility\niris_rf &lt;- randomForest(Species ~ ., data=iris, ntree=100)\n\nStep 7: Evaluating the Model\n\nprint(iris_rf)\n\n\nCall:\n randomForest(formula = Species ~ ., data = iris, ntree = 100) \n               Type of random forest: classification\n                     Number of trees: 100\nNo. of variables tried at each split: 2\n\n        OOB estimate of  error rate: 4.67%\nConfusion matrix:\n           setosa versicolor virginica class.error\nsetosa         50          0         0        0.00\nversicolor      0         47         3        0.06\nvirginica       0          4        46        0.08\n\nimportance(iris_rf)\n\n             MeanDecreaseGini\nSepal.Length          8.80428\nSepal.Width           2.15148\nPetal.Length         36.36521\nPetal.Width          51.88037\n\n\nStep 8: Visualizing Model Performance\n\nplot(iris_rf)\n\n\n\n\nStep 9: Making Predictions\n\nnew_data &lt;- data.frame(Sepal.Length=5.1, Sepal.Width=3.5, Petal.Length=1.4, Petal.Width=0.2)\nprediction &lt;- predict(iris_rf, new_data)\nprint(prediction)\n\n     1 \nsetosa \nLevels: setosa versicolor virginica"
  },
  {
    "objectID": "blogs/index.html#mastering-random-forest-in-rstudio",
    "href": "blogs/index.html#mastering-random-forest-in-rstudio",
    "title": "Intro to Random Forest in RStudio",
    "section": "",
    "text": "I’ve always found Random Forest to be a fascinating and robust machine learning technique, ideal for both classification and regression tasks. It’s like crafting a forest of decision trees where each tree contributes to a more accurate and generalized prediction. Recently, I delved into implementing a Random Forest model in RStudio, and here, I’ll share my experience using the well-known iris dataset.\nRStudio has been my go-to for exploring machine learning models, and Random Forest was no exception. The iris dataset, a staple in R’s dataset collection, was my dataset of choice for this exploration.\nStep 1: Installing and Loading Packages\n\nlibrary(randomForest)\n\nrandomForest 4.7-1.1\n\n\nType rfNews() to see new features/changes/bug fixes.\n\nlibrary(ggplot2)\n\n\nAttaching package: 'ggplot2'\n\n\nThe following object is masked from 'package:randomForest':\n\n    margin\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following object is masked from 'package:randomForest':\n\n    combine\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\nStep 2: Loading the Dataset\n\ndata(\"iris\")\n\nStep 3: Exploring the Dataset\n\ncolnames(iris)\n\n[1] \"Sepal.Length\" \"Sepal.Width\"  \"Petal.Length\" \"Petal.Width\"  \"Species\"     \n\nstr(iris)\n\n'data.frame':   150 obs. of  5 variables:\n $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\n $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n $ Species     : Factor w/ 3 levels \"setosa\",\"versicolor\",..: 1 1 1 1 1 1 1 1 1 1 ...\n\nsummary(iris)\n\n  Sepal.Length    Sepal.Width     Petal.Length    Petal.Width   \n Min.   :4.300   Min.   :2.000   Min.   :1.000   Min.   :0.100  \n 1st Qu.:5.100   1st Qu.:2.800   1st Qu.:1.600   1st Qu.:0.300  \n Median :5.800   Median :3.000   Median :4.350   Median :1.300  \n Mean   :5.843   Mean   :3.057   Mean   :3.758   Mean   :1.199  \n 3rd Qu.:6.400   3rd Qu.:3.300   3rd Qu.:5.100   3rd Qu.:1.800  \n Max.   :7.900   Max.   :4.400   Max.   :6.900   Max.   :2.500  \n       Species  \n setosa    :50  \n versicolor:50  \n virginica :50  \n                \n                \n                \n\n\nStep 4: Visualizing the Data\nTo get a better grasp of the data distribution, I created some visualizations.\n\npar(mfrow = c(2, 2), mar = c(4, 4, 2, 1))\nboxplot(iris$Sepal.Length, main = \"Sepal Length\",col = \"green\", border = \"black\")\nboxplot(iris$Sepal.Width, main = \"Sepal Width\",col = \"green\", border = \"black\")\nboxplot(iris$Petal.Length, main = \"Petal Length\",col = \"green\", border = \"black\")\nboxplot(iris$Petal.Width, main = \"Petal Width\",col = \"green\", border = \"black\")\n\n\n\n\nStep 5: Examining Relationships\nI wanted to explore relationships between variables, particularly focusing on how different features correlate with iris species. For this, scatterplots are excellent.\n\npairs(iris[1:4], main = \"Iris Data - Pairwise Scatterplot\", \n      pch = 21, bg = c(\"red\", \"green3\", \"blue\")[unclass(iris$Species)])\n\n\n\n\nStep 6: Building the Random Forest Model\n\nset.seed(123)  # For reproducibility\niris_rf &lt;- randomForest(Species ~ ., data=iris, ntree=100)\n\nStep 7: Evaluating the Model\n\nprint(iris_rf)\n\n\nCall:\n randomForest(formula = Species ~ ., data = iris, ntree = 100) \n               Type of random forest: classification\n                     Number of trees: 100\nNo. of variables tried at each split: 2\n\n        OOB estimate of  error rate: 4.67%\nConfusion matrix:\n           setosa versicolor virginica class.error\nsetosa         50          0         0        0.00\nversicolor      0         47         3        0.06\nvirginica       0          4        46        0.08\n\nimportance(iris_rf)\n\n             MeanDecreaseGini\nSepal.Length          8.80428\nSepal.Width           2.15148\nPetal.Length         36.36521\nPetal.Width          51.88037\n\n\nStep 8: Visualizing Model Performance\n\nplot(iris_rf)\n\n\n\n\nStep 9: Making Predictions\n\nnew_data &lt;- data.frame(Sepal.Length=5.1, Sepal.Width=3.5, Petal.Length=1.4, Petal.Width=0.2)\nprediction &lt;- predict(iris_rf, new_data)\nprint(prediction)\n\n     1 \nsetosa \nLevels: setosa versicolor virginica"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "Intro to Random Forest in RStudio\n\n\n\n\n\n\n\n\n\n\n\n\nDec 11, 2023\n\n\nSaran Kumar\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Saran Kumar Vajja",
    "section": "",
    "text": "Saran Kumar is currently pursuing his Masters of Science in Advanced Data Analytics at the University of North Texas.He completed his Bachelors of Commerce in Computer Applications from Sri Venkateswara University.\nWorked on Prediction of House sales price and Electric vehicle analysis projects.\nProficient in Python, C, C++, RStudio,Tableau, Power BI, Google Cloud Platform.\n \n    \n  \n    \n     Email\n  \n  \n    \n     GitHub\n  \n  \n    \n     Resume\n  \n  \n    \n     Linkedin"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  }
]